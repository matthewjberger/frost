// Character constants
EOF_CHAR :: 0
CHAR_SPACE :: 32
CHAR_TAB :: 9
CHAR_NEWLINE :: 10
CHAR_CARRIAGE_RETURN :: 13
CHAR_BANG :: 33
CHAR_DOUBLE_QUOTE :: 34
CHAR_HASH :: 35
CHAR_DOLLAR :: 36
CHAR_PERCENT :: 37
CHAR_AMPERSAND :: 38
CHAR_SINGLE_QUOTE :: 39
CHAR_LEFT_PAREN :: 40
CHAR_RIGHT_PAREN :: 41
CHAR_ASTERISK :: 42
CHAR_PLUS :: 43
CHAR_COMMA :: 44
CHAR_MINUS :: 45
CHAR_DOT :: 46
CHAR_SLASH :: 47
CHAR_ZERO :: 48
CHAR_NINE :: 57
CHAR_COLON :: 58
CHAR_SEMICOLON :: 59
CHAR_LESS_THAN :: 60
CHAR_EQUALS :: 61
CHAR_GREATER_THAN :: 62
CHAR_QUESTION :: 63
CHAR_AT :: 64
CHAR_UPPER_A :: 65
CHAR_UPPER_F :: 70
CHAR_UPPER_Z :: 90
CHAR_LEFT_BRACKET :: 91
CHAR_BACKSLASH :: 92
CHAR_RIGHT_BRACKET :: 93
CHAR_CARET :: 94
CHAR_UNDERSCORE :: 95
CHAR_BACKTICK :: 96
CHAR_LOWER_A :: 97
CHAR_LOWER_F :: 102
CHAR_LOWER_Z :: 122
CHAR_LEFT_BRACE :: 123
CHAR_PIPE :: 124
CHAR_RIGHT_BRACE :: 125

Token :: enum {
    Ampersand,
    And,
    Arrow,
    Assign,
    Asterisk,
    Bang,
    Break,
    Caret,
    Case,
    Colon,
    ColonAssign,
    Comma,
    Comptime,
    Context,
    Continue,
    Defer,
    Distinct,
    Dollar,
    DoubleColon,
    Dot,
    DotDot,
    DotDotEqual,
    Else,
    EndOfFile,
    Enum,
    Extern,
    Equal,
    False,
    For,
    Function,
    GreaterThan,
    GreaterThanOrEqual,
    Hash,
    Identifier { name: str },
    If,
    Illegal { value: str },
    Import,
    In,
    Integer { value: i64 },
    Float { text: str },
    Float32 { text: str },
    LeftBrace,
    LeftBracket,
    LeftParentheses,
    LessThan,
    LessThanOrEqual,
    Let,
    Minus,
    Match,
    Mut,
    NotEqual,
    Or,
    Percent,
    Pipe,
    Plus,
    PushAllocator,
    PushContext,
    Question,
    Return,
    RightBrace,
    RightBracket,
    RightParentheses,
    Semicolon,
    ShiftLeft,
    ShiftRight,
    Sizeof,
    Slash,
    StringLiteral { value: str },
    Struct,
    True,
    Type,
    Typename,
    TypeBool,
    TypeF32,
    TypeF64,
    TypeI8,
    TypeI16,
    TypeI32,
    TypeI64,
    TypeIsize,
    TypeStr,
    TypeU8,
    TypeU16,
    TypeU32,
    TypeU64,
    TypeUsize,
    TypeVoid,
    Underscore,
    Unsafe,
    Using,
    While,
}

Lexer :: struct {
    position: i64,
    length: i64,
    source: str,
}

lexer_new :: fn(s: str) -> Lexer {
    source := s;
    source_length := len(source);
    Lexer {
        position = 0,
        length = source_length,
        source = source,
    }
}

is_whitespace :: fn(c: i64) -> bool {
    c == CHAR_SPACE || c == CHAR_TAB || c == CHAR_NEWLINE || c == CHAR_CARRIAGE_RETURN
}

is_digit :: fn(c: i64) -> bool {
    c >= CHAR_ZERO && c <= CHAR_NINE
}

is_alpha :: fn(c: i64) -> bool {
    (c >= CHAR_UPPER_A && c <= CHAR_UPPER_Z) || (c >= CHAR_LOWER_A && c <= CHAR_LOWER_Z) || c == CHAR_UNDERSCORE
}

is_alphanumeric :: fn(c: i64) -> bool {
    is_alpha(c) || is_digit(c)
}

peek :: fn(lexer: &Lexer) -> i64 {
    if (lexer.position >= lexer.length) {
        EOF_CHAR
    } else {
        char_at(lexer.source, lexer.position)
    }
}

peek_nth :: fn(lexer: &Lexer, n: i64) -> i64 {
    if (lexer.position + n >= lexer.length) {
        EOF_CHAR
    } else {
        char_at(lexer.source, lexer.position + n)
    }
}

is_eof :: fn(lexer: &Lexer) -> bool {
    lexer.position >= lexer.length
}

read_char :: fn(lexer: &mut Lexer) -> i64 {
    c := peek(lexer);
    lexer.position = lexer.position + 1;
    c
}

skip_whitespace :: fn(lexer: &mut Lexer) {
    while (!is_eof(lexer) && is_whitespace(peek(lexer))) {
        read_char(lexer);
    }
}

take_while_digit :: fn(lexer: &mut Lexer) -> str {
    start := lexer.position;
    while (!is_eof(lexer) && is_digit(peek(lexer))) {
        read_char(lexer);
    }
    substr(lexer.source, start, lexer.position - start)
}

take_while_alphanumeric :: fn(lexer: &mut Lexer) -> str {
    start := lexer.position;
    while (!is_eof(lexer) && is_alphanumeric(peek(lexer))) {
        read_char(lexer);
    }
    substr(lexer.source, start, lexer.position - start)
}

lookup_identifier :: fn(id: str) -> Token {
    identifier := id;
    if (identifier == "_") { return Token::Underscore; }
    if (identifier == "fn") { return Token::Function; }
    if (identifier == "mut") { return Token::Mut; }
    if (identifier == "true") { return Token::True; }
    if (identifier == "false") { return Token::False; }
    if (identifier == "return") { return Token::Return; }
    if (identifier == "if") { return Token::If; }
    if (identifier == "import") { return Token::Import; }
    if (identifier == "let") { return Token::Let; }
    if (identifier == "else") { return Token::Else; }
    if (identifier == "struct") { return Token::Struct; }
    if (identifier == "enum") { return Token::Enum; }
    if (identifier == "extern") { return Token::Extern; }
    if (identifier == "defer") { return Token::Defer; }
    if (identifier == "using") { return Token::Using; }
    if (identifier == "while") { return Token::While; }
    if (identifier == "for") { return Token::For; }
    if (identifier == "in") { return Token::In; }
    if (identifier == "distinct") { return Token::Distinct; }
    if (identifier == "sizeof") { return Token::Sizeof; }
    if (identifier == "break") { return Token::Break; }
    if (identifier == "continue") { return Token::Continue; }
    if (identifier == "match") { return Token::Match; }
    if (identifier == "type") { return Token::Type; }
    if (identifier == "typename") { return Token::Typename; }
    if (identifier == "case") { return Token::Case; }
    if (identifier == "comptime") { return Token::Comptime; }
    if (identifier == "context") { return Token::Context; }
    if (identifier == "push_allocator") { return Token::PushAllocator; }
    if (identifier == "push_context") { return Token::PushContext; }
    if (identifier == "unsafe") { return Token::Unsafe; }
    if (identifier == "i8") { return Token::TypeI8; }
    if (identifier == "i16") { return Token::TypeI16; }
    if (identifier == "i32") { return Token::TypeI32; }
    if (identifier == "i64") { return Token::TypeI64; }
    if (identifier == "isize") { return Token::TypeIsize; }
    if (identifier == "u8") { return Token::TypeU8; }
    if (identifier == "u16") { return Token::TypeU16; }
    if (identifier == "u32") { return Token::TypeU32; }
    if (identifier == "u64") { return Token::TypeU64; }
    if (identifier == "usize") { return Token::TypeUsize; }
    if (identifier == "f32") { return Token::TypeF32; }
    if (identifier == "f64") { return Token::TypeF64; }
    if (identifier == "bool") { return Token::TypeBool; }
    if (identifier == "str") { return Token::TypeStr; }
    if (identifier == "void") { return Token::TypeVoid; }
    Token::Identifier { name = identifier }
}

next_char_or :: fn(lexer: &mut Lexer, default: Token, next_char: i64, token: Token) -> Token {
    if (peek(lexer) == next_char) {
        read_char(lexer);
        token
    } else {
        default
    }
}

next_token :: fn(lexer: &mut Lexer) -> Token {
    skip_whitespace(lexer);
    first_char := read_char(lexer);

    if (first_char == CHAR_EQUALS) {
        return next_char_or(lexer, Token::Assign, CHAR_EQUALS, Token::Equal);
    }
    if (first_char == CHAR_SEMICOLON) { return Token::Semicolon; }
    if (first_char == CHAR_LEFT_PAREN) { return Token::LeftParentheses; }
    if (first_char == CHAR_RIGHT_PAREN) { return Token::RightParentheses; }
    if (first_char == CHAR_COMMA) { return Token::Comma; }
    if (first_char == CHAR_COLON) {
        if (peek(lexer) == CHAR_COLON) {
            read_char(lexer);
            return Token::DoubleColon;
        }
        if (peek(lexer) == CHAR_EQUALS) {
            read_char(lexer);
            return Token::ColonAssign;
        }
        return Token::Colon;
    }
    if (first_char == CHAR_PLUS) { return Token::Plus; }
    if (first_char == CHAR_LEFT_BRACE) { return Token::LeftBrace; }
    if (first_char == CHAR_RIGHT_BRACE) { return Token::RightBrace; }
    if (first_char == CHAR_LEFT_BRACKET) { return Token::LeftBracket; }
    if (first_char == CHAR_RIGHT_BRACKET) { return Token::RightBracket; }
    if (first_char == CHAR_PERCENT) { return Token::Percent; }
    if (first_char == CHAR_QUESTION) { return Token::Question; }
    if (first_char == CHAR_CARET) { return Token::Caret; }
    if (first_char == CHAR_HASH) { return Token::Hash; }
    if (first_char == CHAR_DOLLAR) { return Token::Dollar; }

    if (first_char == CHAR_MINUS) {
        return next_char_or(lexer, Token::Minus, CHAR_GREATER_THAN, Token::Arrow);
    }
    if (first_char == CHAR_ASTERISK) { return Token::Asterisk; }

    if (first_char == CHAR_SLASH) {
        if (peek(lexer) == CHAR_SLASH) {
            while (!is_eof(lexer) && peek(lexer) != CHAR_NEWLINE) {
                read_char(lexer);
            }
            return next_token(lexer);
        }
        if (peek(lexer) == CHAR_ASTERISK) {
            read_char(lexer);
            while (true) {
                if (is_eof(lexer)) {
                    return Token::Illegal { value = "Unterminated block comment" };
                }
                if (peek(lexer) == CHAR_ASTERISK && peek_nth(lexer, 1) == CHAR_SLASH) {
                    read_char(lexer);
                    read_char(lexer);
                    break;
                }
                read_char(lexer);
            }
            return next_token(lexer);
        }
        return Token::Slash;
    }

    if (first_char == CHAR_AMPERSAND) {
        return next_char_or(lexer, Token::Ampersand, CHAR_AMPERSAND, Token::And);
    }

    if (first_char == CHAR_PIPE) {
        return next_char_or(lexer, Token::Pipe, CHAR_PIPE, Token::Or);
    }

    if (first_char == CHAR_DOT) {
        if (peek(lexer) == CHAR_DOT) {
            read_char(lexer);
            if (peek(lexer) == CHAR_EQUALS) {
                read_char(lexer);
                return Token::DotDotEqual;
            }
            return Token::DotDot;
        }
        return Token::Dot;
    }

    if (first_char == CHAR_LESS_THAN) {
        if (peek(lexer) == CHAR_LESS_THAN) {
            read_char(lexer);
            return Token::ShiftLeft;
        }
        if (peek(lexer) == CHAR_EQUALS) {
            read_char(lexer);
            return Token::LessThanOrEqual;
        }
        return Token::LessThan;
    }

    if (first_char == CHAR_GREATER_THAN) {
        if (peek(lexer) == CHAR_GREATER_THAN) {
            read_char(lexer);
            return Token::ShiftRight;
        }
        if (peek(lexer) == CHAR_EQUALS) {
            read_char(lexer);
            return Token::GreaterThanOrEqual;
        }
        return Token::GreaterThan;
    }

    if (first_char == CHAR_BANG) {
        return next_char_or(lexer, Token::Bang, CHAR_EQUALS, Token::NotEqual);
    }

    if (first_char == CHAR_DOUBLE_QUOTE) {
        start := lexer.position;
        while (!is_eof(lexer) && peek(lexer) != CHAR_DOUBLE_QUOTE) {
            read_char(lexer);
        }
        if (is_eof(lexer)) {
            return Token::Illegal { value = "Unterminated string literal" };
        }
        literal := substr(lexer.source, start, lexer.position - start);
        read_char(lexer);
        return Token::StringLiteral { value = literal };
    }

    if (first_char == EOF_CHAR) {
        return Token::EndOfFile;
    }

    if (is_alpha(first_char)) {
        start := lexer.position - 1;
        take_while_alphanumeric(lexer);
        identifier := substr(lexer.source, start, lexer.position - start);
        return lookup_identifier(identifier);
    }

    if (is_digit(first_char)) {
        start := lexer.position - 1;
        take_while_digit(lexer);
        if (peek(lexer) == CHAR_DOT && peek_nth(lexer, 1) != CHAR_DOT) {
            read_char(lexer);
            take_while_digit(lexer);
            if (peek(lexer) == CHAR_LOWER_F) {
                read_char(lexer);
                if (peek(lexer) == CHAR_ZERO + 3 && peek_nth(lexer, 1) == CHAR_ZERO + 2) {
                    read_char(lexer);
                    read_char(lexer);
                }
                number_str := substr(lexer.source, start, lexer.position - start - 3);
                return Token::Float32 { text = number_str };
            }
            number_str := substr(lexer.source, start, lexer.position - start);
            return Token::Float { text = number_str };
        }
        number_str := substr(lexer.source, start, lexer.position - start);
        return Token::Integer { value = parse_int(number_str) };
    }

    Token::Illegal { value = "Unknown character" }
}

tokenize :: fn(lexer: &mut Lexer) -> []Token {
    mut tokens : []Token = [];
    while (true) {
        skip_whitespace(lexer);
        if (is_eof(lexer)) {
            break;
        }
        tok := next_token(lexer);
        tokens = push(tokens, tok);
    }
    tokens
}

test_lexer :: fn() {
    print("Testing lexer...");

    mut lexer := lexer_new("42 + x");

    tok1 := next_token(&mut lexer);
    match tok1 {
        case .Integer { value }: {
            assert(value == 42, "Expected integer 42");
        }
        case _: {
            print("FAIL: Expected Integer token");
        }
    }

    tok2 := next_token(&mut lexer);
    match tok2 {
        case .Plus: {
            print("OK: Plus token");
        }
        case _: {
            print("FAIL: Expected Plus token");
        }
    }

    tok3 := next_token(&mut lexer);
    match tok3 {
        case .Identifier { name }: {
            assert(name == "x", "Expected identifier x");
        }
        case _: {
            print("FAIL: Expected Identifier token");
        }
    }

    print("Lexer tests passed!");
}

test_new_tokens :: fn() {
    print("Testing new tokens...");

    mut lexer1 := lexer_new("$T");
    tok1 := next_token(&mut lexer1);
    match tok1 {
        case .Dollar: { print("OK: Dollar"); }
        case _: { print("FAIL: Expected Dollar"); }
    }

    mut lexer2 := lexer_new("..=");
    tok2 := next_token(&mut lexer2);
    match tok2 {
        case .DotDotEqual: { print("OK: DotDotEqual"); }
        case _: { print("FAIL: Expected DotDotEqual"); }
    }

    mut lexer3 := lexer_new("let");
    tok3 := next_token(&mut lexer3);
    match tok3 {
        case .Let: { print("OK: Let"); }
        case _: { print("FAIL: Expected Let"); }
    }

    mut lexer4 := lexer_new("isize");
    tok4 := next_token(&mut lexer4);
    match tok4 {
        case .TypeIsize: { print("OK: TypeIsize"); }
        case _: { print("FAIL: Expected TypeIsize"); }
    }

    mut lexer5 := lexer_new("usize");
    tok5 := next_token(&mut lexer5);
    match tok5 {
        case .TypeUsize: { print("OK: TypeUsize"); }
        case _: { print("FAIL: Expected TypeUsize"); }
    }

    mut lexer6 := lexer_new("context");
    tok6 := next_token(&mut lexer6);
    match tok6 {
        case .Context: { print("OK: Context"); }
        case _: { print("FAIL: Expected Context"); }
    }

    mut lexer7 := lexer_new("push_allocator");
    tok7 := next_token(&mut lexer7);
    match tok7 {
        case .PushAllocator: { print("OK: PushAllocator"); }
        case _: { print("FAIL: Expected PushAllocator"); }
    }

    mut lexer8 := lexer_new("push_context");
    tok8 := next_token(&mut lexer8);
    match tok8 {
        case .PushContext: { print("OK: PushContext"); }
        case _: { print("FAIL: Expected PushContext"); }
    }

    print("New token tests passed!");
}

test_lexer();
test_new_tokens();
print("Frost lexer module loaded successfully")
